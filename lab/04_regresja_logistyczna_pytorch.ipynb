{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "import checker\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wstęp do PyTorcha\n",
    "* PyTorch to biblioteka do uczenia maszynowego, w szczególności głębokiego.\n",
    "\n",
    "**Interfejs** jest bardzo podobny do numpy, z wyjątkiem pewnych zmian:\n",
    "* Zamiast `numpy.ndarray` naszym podstawowym obiektem będzie teraz `torch.Tensor`. Tensor, czyli uogólnienie macierzy do wyższych wymiarów.\n",
    "* Jeśli chcemy zsumować macierz `A` po pierwszym wymiarze, w numpy zrobilibyśmy `A.sum(axis=0)`. W PyTorch zamiast tego używamy argumentu `dim`: `A.sum(dim=0)`.\n",
    "* Zamiast `np.concatenate` jest `torch.cat`.\n",
    "* Zamiast `np.power` jest `torch.pow`.\n",
    "* I tym podobne.\n",
    "\n",
    "W nowszych wersjach PyTorcha [pojawia się coraz więcej podobieństw do NumPy](https://github.com/pytorch/pytorch/issues/38349), co pozwala m. in. używać argumentu `axis` wymiennie z `dim`. Przy przechodzeniu między tymi dwiema bibliotekami warto jednak uważać, gdyż nie wszystkie metody zachowują się w identyczny sposób.\n",
    "\n",
    "\n",
    "\n",
    "Przejście z `numpy.ndarray` do `torch.Tensor` (i na odwrót) jest bardzo proste:\n",
    "* `A (numpy.ndarray) -> B (torch.Tensor)`: `B = torch.from_numpy(A)`\n",
    "* `B (torch.Tensor) -> A (numpy.ndarray)`: `A = B.numpy()`\n",
    "    \n",
    "Kluczowe różnice:\n",
    "* PyTorch **automatycznie liczy dla nas gradienty**. Nie musimy własnoręcznie liczyć na kartce wzoru na gradient a potem przepisywać go do programu.\n",
    "* PyTorch ma **wsparcie dla GPU**, co umożliwia szybkie obliczenia w sieciach neuronowych.\n",
    "\n",
    "Dobre materiały do nauki PyTorcha: [Deep Learning in 60 minutes](https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html), [PyTorch Examples](https://github.com/pytorch/examples).\n",
    "\n",
    "Drobna uwaga - te tutoriale opisują abstrakcje takie jak `torch.nn.Module`, `torch.optim.SGD` czy `torch.utils.data`, którymi będziemy się zajmować od kolejnych zajęć. Na tych zajęciach spróbujemy zobaczyć, co PyTorch robi \"pod spodem\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automatyczne różniczkowanie w PyTorchu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def gradient_descent(loss, X, parameters, y=None, lr=1e-6, num_steps=int(1e4)):\n",
    "    for idx in range(num_steps):\n",
    "        # Informujemy PyTorcha, że chcemy dostać gradient po naszych parametrach\n",
    "        parameters.requires_grad = True\n",
    "        \n",
    "        # Liczymy wartość funkcji kosztu.\n",
    "        loss_val = loss(X, parameters, y)\n",
    "        \n",
    "        # Każemy PyTorchowi policzyć gradient\n",
    "        loss_val.backward()\n",
    "        \n",
    "        # Wyciągamy gradient po parametrach\n",
    "        gradient = parameters.grad\n",
    "\n",
    "        # Wykonujemy krok metody spadku gradientu\n",
    "        with torch.no_grad():\n",
    "            parameters = parameters - lr * gradient\n",
    "    \n",
    "    # Zwracamy najlepsze parametry\n",
    "    return parameters\n",
    "\n",
    "# Dziwna funkcja, której minimum będziemy chcieli znaleźć.\n",
    "def complex_fn(a, x, _=None):\n",
    "    y = a[0] / a[1] * torch.cos(a[0] * x ** 2 + a[1] * x - a[2])\n",
    "    z = torch.exp(-x) / (y + 3)\n",
    "    return -(z + y) + torch.exp(-x - 0.8)\n",
    "\n",
    "a = torch.tensor([3., 5., 1.])\n",
    "x = torch.tensor(-4.)\n",
    "result = gradient_descent(complex_fn, a, x, lr=2e-2, num_steps=int(2e4))\n",
    "\n",
    "utils.plot_torch_fn(complex_fn, a, x, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing datasets\n",
    "torch.manual_seed(5)\n",
    "\n",
    "# Regression dataset - Boston housing (https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_boston.html)\n",
    "\n",
    "data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
    "raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
    "boston_data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
    "boston_target = raw_df.values[1::2, 2]\n",
    "      \n",
    "boston_X = torch.tensor(boston_data, dtype=torch.float32)\n",
    "boston_y = torch.tensor(boston_target, dtype=torch.float32)\n",
    "boston_w = torch.randn(boston_X.shape[1], dtype=torch.float32, requires_grad=True)\n",
    "\n",
    "\n",
    "boston_data = (boston_X, boston_y, boston_w)\n",
    "\n",
    "# Multidimensional datasets\n",
    "dataset_5d = torch.randn([1000, 5], dtype=torch.float32)\n",
    "param_5d = torch.randn(5, requires_grad=True)\n",
    "\n",
    "dataset_20d = torch.randn([325, 20], dtype=torch.float32)\n",
    "param_20d = torch.randn(20, requires_grad=True)\n",
    "\n",
    "multi_datasets = [(dataset_5d, param_5d), (dataset_20d, param_20d)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie 1 (2 pkt.)\n",
    "\n",
    "Zaimplementuj w PyTorchu funkcje kosztu, które minimalizowaliśmy na wcześniejszych ćwiczeniach. Czyli konkretnie:\n",
    "* `mean_squared_error` (lab 02)\n",
    "* `mean_error` (lab 02)\n",
    "* `max_error` (lab 02)\n",
    "* `linear_regression_loss` (lab 03)\n",
    "* `regularized_regression_loss` (lab 03)\n",
    "\n",
    "Proszę te funkcje przekleić (ze swoich rozwiązań czy też oficjalnych) i przerobić tak, żeby przyjmowały `torch.Tensor` zamiast `np.ndarray` oraz zwracały `torch.Tensor`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_squared_error(X: torch.Tensor, theta: torch.Tensor) -> torch.Tensor:\n",
    "    squared_distances = torch.sum(torch.pow(X - theta, 2), dim=-1)\n",
    "    return torch.mean(squared_distances)\n",
    "\n",
    "checker.check_4_1_mse(mean_squared_error, multi_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "err: 2.432988166809082, loss 2.433000087738037\n",
      "err: 6.155062675476074, loss 6.155099868774414\n"
     ]
    }
   ],
   "source": [
    "def mean_error(X: torch.Tensor, theta: torch.Tensor) -> torch.Tensor:\n",
    "    # print(X.shape)\n",
    "    # print(theta.shape)\n",
    "    squared_distances = torch.mean(torch.linalg.norm(X - theta, dim=-1))\n",
    "    return squared_distances\n",
    "\n",
    "results = [torch.tensor(2.4330), torch.tensor(6.1551)]\n",
    "for (data, param), loss in zip(multi_datasets, results):\n",
    "    print(f\"err: {mean_error(data, param)}, loss {loss}\")\n",
    "checker.check_4_1_me(mean_error, multi_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "err: 725.7027587890625, loss 5.708600044250488\n",
      "err: 257.86798095703125, loss 8.805700302124023\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Wrong loss returned!",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAssertionError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/yk/k64l2mhn76v6pplzldkddm0c0000gr/T/ipykernel_44037/1776107688.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mparam\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mloss\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mzip\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmulti_datasets\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mresults\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      7\u001B[0m     \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34mf\"err: {max_error(data, param)}, loss {loss}\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 8\u001B[0;31m \u001B[0mchecker\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcheck_4_1_max\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmax_error\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmulti_datasets\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m~/Desktop/python/ml2022-23/lab/checker.py\u001B[0m in \u001B[0;36mcheck_4_1_max\u001B[0;34m(fn, datasets)\u001B[0m\n\u001B[1;32m    170\u001B[0m     \u001B[0mresults\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtensor\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m5.7086\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtensor\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m8.8057\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    171\u001B[0m     \u001B[0;32mfor\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mparam\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mloss\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mzip\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdatasets\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mresults\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 172\u001B[0;31m         \u001B[0;32massert\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mallclose\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mparam\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mloss\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"Wrong loss returned!\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    173\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    174\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0mcheck_4_1_lin_reg\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfn\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdata\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mAssertionError\u001B[0m: Wrong loss returned!"
     ]
    }
   ],
   "source": [
    "def max_error(X: torch.Tensor, theta: torch.Tensor) -> torch.Tensor:\n",
    "    norms = torch.linalg.norm(X - theta, ord=-1)\n",
    "    return torch.max(norms)\n",
    "\n",
    "results = [torch.tensor(5.7086), torch.tensor(8.8057)]\n",
    "for (data, param), loss in zip(multi_datasets, results):\n",
    "    print(f\"err: {max_error(data, param)}, loss {loss}\")\n",
    "checker.check_4_1_max(max_error, multi_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_regression_loss(X: torch.Tensor, w: torch.Tensor, y: torch.Tensor) -> torch.Tensor:\n",
    "    diff = torch.matmul(X, w) - y\n",
    "    return torch.sum(diff * diff) / diff.numel()\n",
    "\n",
    "\n",
    "checker.check_4_1_lin_reg(linear_regression_loss, boston_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "err: 51010068.0, loss 100910.8671875\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Wrong loss returned!",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAssertionError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/yk/k64l2mhn76v6pplzldkddm0c0000gr/T/ipykernel_44037/3250671475.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      8\u001B[0m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34mf\"err: {regularized_regression_loss(X, w, y)}, loss {torch.tensor(100910.8672)}\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      9\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 10\u001B[0;31m \u001B[0mchecker\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcheck_4_1_reg_reg\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mregularized_regression_loss\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mboston_data\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m~/Desktop/python/ml2022-23/lab/checker.py\u001B[0m in \u001B[0;36mcheck_4_1_reg_reg\u001B[0;34m(fn, data)\u001B[0m\n\u001B[1;32m    178\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0mcheck_4_1_reg_reg\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfn\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdata\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    179\u001B[0m     \u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mw\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdata\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 180\u001B[0;31m     \u001B[0;32massert\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mallclose\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mw\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtensor\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m100910.8672\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"Wrong loss returned!\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    181\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    182\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mAssertionError\u001B[0m: Wrong loss returned!"
     ]
    }
   ],
   "source": [
    "def regularized_regression_loss(X: torch.Tensor, w: torch.Tensor, y: torch.Tensor) -> torch.Tensor:\n",
    "    alpha = 0.2\n",
    "    pred = torch.matmul(X, w) + alpha\n",
    "    return mean_squared_error(pred, y)\n",
    "\n",
    "\n",
    "X, y, w = boston_data\n",
    "print(f\"err: {regularized_regression_loss(X, w, y)}, loss {torch.tensor(100910.8672)}\")\n",
    "\n",
    "checker.check_4_1_reg_reg(regularized_regression_loss, boston_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Część 1: Regresja logistyczna\n",
    "\n",
    "## Klasyfikacja\n",
    "\n",
    "Dzisiaj na zajęciach zajmiemy się problemem klasyfikacji. Podobnie do regresji liniowej jest to przykład uczenia nadzorowanego, ale zamiast przewidywać konkretną liczbę dla danej obserwacji, przewidujemy jego przynajeżność do jednej z *k* klas. Na tych zajęciach będziemy rozważać klasyfikacje binarną, czyli uczyć modele odpowiadające funkcji:\n",
    "\n",
    "$$ f(x) = y, \\quad y \\in \\{0,1\\} $$\n",
    "\n",
    "## Modele probabilistyczne i decyzyjne\n",
    "Przyjmujemy, że mamy zadanie klasyfikacji binarnej (dwie klasy). Na wykładzie poznaliśmy co najmniej dwie metody klasyfikacji:\n",
    "\n",
    "1. Support Vector Machine, który dla zadanego przykładu podaje nam po prostu jego przewidzianą klasę $y$\n",
    "2. Regresję logistyczną, która zwraca rozkład na klasach.\n",
    "\n",
    "SVM tym samym nie jest jednak w stanie powiedzieć nam jak bardzo pewny jest swojej decyzji, regresja logistyczna potrafi to osiągnąć. Na tej podstawie możemy stworzyć sobie następujący podział modeli klasyfikacyjnych:\n",
    "\n",
    "* **Modele decyzyjne** - są w stanie odpowiedzieć nam, jaki jest najbardziej prawdopodobna etykieta $y$ dla przykładu $x$, ale nie dają rozkładu prawdopodobieństwa.\n",
    "* **Modele probabilistyczne** - zadają nam rozkład na etykietach $p(y \\mid x)$, dzięki czemu dostajemy więcej informacji.\n",
    "\n",
    "**Pytanie:** Dlaczego może nas interesować cały rozkład prawdopodobieństwa zamiast najbardziej prawdopodobnej odpowiedzi?\n",
    "\n",
    "## Regresja logistyczna jako model probabilistyczny\n",
    "Chcielibyśmy stworzyć model, który otrzymując na wejściu $x$ będzie w stanie nam powiedzieć, jakie jest prawdopodobieństwo, że $y = 0$. Tzn, jeśli nasz model to funkcja $g(x)$, to nasza funkcja ma zadawać rozkład prawdopodobieństwa:\n",
    "\n",
    "$$g(x) = \\hat{p}(y = 1 \\mid x)$$\n",
    "\n",
    "Z tego możemy łatwo wyciągnąć prawdopodobieństwo, że zadany przykład ma etykietę $0$, tzn:\n",
    "$$ \\hat{p}(y = 0 \\mid x) = 1 - \\hat{p}(y = 1 \\mid x) = 1 - g(x) $$\n",
    "\n",
    "\n",
    "**Pytanie:** Kiedy będziemy mieli model zadający nam rozkład $\\hat{p}(y \\mid x)$, jak odpowiedzieć na pytanie \"jaka jest etykieta zadanego przykładu\"?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresja logistyczna na podstawie regresji liniowej\n",
    "\n",
    "**Problem:** Jak uzyskać probabilistyczny model klasyfikacyjny? Moglibyśmy użyć naszego modelu liniowego o postaci $f(x) = w^Tx + b$, ale ten model ma wadę: może przewidywać dowolne wartości ze zbioru liczb rzeczywistych, tzn. $f(x) \\in \\mathbb{R}$, natomiast z definicji prawdopodobieństwo $p(y=1) \\in [0, 1]$.\n",
    "\n",
    "*Uwaga: Wcześniej nasz model liniowy był postaci $f(x) = w^Tx$, teraz dodaliśmy jeszcze tzw. bias $b \\in \\mathbb{R}$, który pozwala nam reprezentować przekształcenia afiniczne, a nie tylko liniowe.* \n",
    "\n",
    "**Rozwiązanie:** Potrzebujemy więc funkcji, która \"spłaszczy\" nam przedział $\\mathbb{R}$ do $[0, 1]$. Można by taką funkcję znaleźć na wiele sposobów, ale z powodów technicznych najczęściej korzysta się z sigmoidy, tzn.:\n",
    "$$ \\sigma(x) = \\frac{1}{1 + \\exp(-x)} $$\n",
    "\n",
    "**Wykres funkcji sigmoid**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"sigma(x)\")\n",
    "\n",
    "X = np.linspace(-6, 6)\n",
    "plt.plot(X, 1 / (1 + np.exp(-X)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ostatecznie nasz model wygląda tak:\n",
    "$$\n",
    "    \\hat{p}(y = 1 \\mid x) = \\sigma(w^Tx + b)\n",
    "$$\n",
    "\n",
    "Mamy więc model, który jest w stanie dać nam rozkład prawdopodobieństwa etykiety pod warunkiem $\\hat{p}(y \\mid x)$. Nasz zbiór treningowy zawiera też próbki z prawdziwego rozkładu prawdopodobieństwa: $p(y_i \\mid x_i)$.\n",
    "\n",
    "Jako funkcję kosztu wybieramy sobie więc \"różnicę\" pomiędzy prawdziwym rozkładem, a rozkładem zadanym przez nasz model. W tym wypadku sprawdza się **entropia krzyżowa** (cross-entropy), zadana wzorem:\n",
    "\n",
    "\n",
    "\\begin{split}\n",
    "      \\mathcal{H}(p(y \\mid x_i), \\hat{p}(y \\mid x_i)) &= -\\sum_{k \\in \\{0, 1\\}} p(y=k \\mid x_i) \\ln \\hat{p}(y=k \\mid x_i) \\\\\n",
    "      &= -p(y = 0 \\mid x_i) \\ln \\hat{p}(y = 0 \\mid x_i) - p(y=1 \\mid x_i) \\ln \\hat{p}(y=1 \\mid x_i) \\\\\n",
    "      &= -(1 - p(y = 1 \\mid x_i)) \\ln (1 - \\hat{p}(y = 1 \\mid x_i)) - p(y=1 \\mid x_i) \\ln \\hat{p}(y=1 \\mid x_i) \\\\\n",
    "      &= - (1 - y_i) \\ln (1 - \\hat{y}) - y_i \\ln \\hat{y} ,\n",
    "\\end{split}\n",
    "gdzie podstawiliśmy sobie: $$\\hat{p}(y=1 \\mid x_i) = \\hat{y}, \\\\ p(y=1 \\mid x_i) = y_i$$\n",
    "\n",
    "Ustalmy teraz, że ostateczną funkcją kosztu naszego modelu będzie średnia entropia krzyżowa dla zbioru danych:\n",
    "$$\n",
    "    \\mathcal{L}(X) = \\frac{1}{N} \\sum_{(x_i, y_i) \\in X}^N  \\mathcal{H}(p(y \\mid x_i), \\hat{p}(y \\mid x_i))\n",
    "$$\n",
    "\n",
    "\n",
    "Taki model możemy teraz optymalizować metodą spadku gradientu i wykorzystać do klasyfikacji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Przygotujmy datasety i funkcje pomocnicze\n",
    "dataset_1d = utils.get_classification_dataset_1d()\n",
    "dataset_2d = utils.get_classification_dataset_2d()\n",
    "\n",
    "def calculate_accuracy(logistic_reg, X, y):\n",
    "    preds = logistic_reg.predict(X)\n",
    "    correct_n = (preds == y).float().sum().item()\n",
    "    return correct_n / len(y)\n",
    "\n",
    "def plot_dataset_1d(logistic_reg, dataset_1d):\n",
    "    plt.scatter(dataset_1d.data[:10], [0.5] * 10, c=\"purple\", label=\"0\")\n",
    "    plt.scatter(dataset_1d.data[10:], [0.5] * 10, c=\"yellow\", label=\"1\")\n",
    "    linspace = torch.linspace(-7.5, 15, steps=100).view(-1, 1)\n",
    "    plt.plot(\n",
    "        linspace.numpy().ravel(),\n",
    "        logistic_reg.predict_proba(linspace).detach().numpy(),\n",
    "        label=\"p(y=1 | x)\"\n",
    "    )\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "def plot_dataset_2d(logistic_reg, dataset_2d):\n",
    "    plt.scatter(dataset_2d.data[:50, 0], dataset_2d.data[:50, 1], c=\"purple\", label=\"0\")\n",
    "    plt.scatter(dataset_2d.data[50:, 0], dataset_2d.data[50:, 1], c=\"yellow\", label=\"1\")\n",
    "\n",
    "    linspace_x = torch.linspace(-4, 7, steps=100)\n",
    "    linspace_y = (-logistic_reg.bias - logistic_reg.weight[0] * linspace_x) / logistic_reg.weight[1]\n",
    "\n",
    "    linspace_y = linspace_y.detach().numpy()\n",
    "    plt.plot(linspace_x.detach().numpy(), linspace_y, label=\"Granica decyzyjna\")\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie 2 (2 pkt.)\n",
    "\n",
    "Zaimplementuj w PyTorchu regresję logistyczną. W tym celu trzeba napisać następujące funkcje:\n",
    "1. Funkcję kosztu modelu regresji logistycznej `loss(X, y)`, według następujących kroków:\n",
    "    * Policz model liniowy $z = w^Tx + b$\n",
    "    * Na wektorze $z$ zaimplementuj funkcję $\\hat{y} = \\sigma(z) = \\frac{1}{1 + \\exp(-z)}$.\n",
    "    * Policz entropię krzyżową pomiędzy predykcjami $\\hat{y}$ a etykietami $y$ zadaną przez:\n",
    "    $\\frac{1}{N} \\sum_i - (1 - y_i) \\ln (1 - \\hat{y}_i) - y_i \\ln \\hat{y}_i$\n",
    "2. Funkcję `predict_proba(X)` zwracającą dla każdego $x_i \\in X$ zadane przez nasz model prawdopodobieństwo $\\hat{p}(y = 1 \\mid x_i)$. \n",
    "3. Funkcję `predict(X)` zwracającą dla każdego $x_i \\in X$ przewidywaną etykietę (tzn. $0$ albo $1$). Zwracana etykieta powinna być typu `float`.\n",
    "\n",
    "**UWAGA** Nie można korzystać z funkcji PyTorcha do liczenia entropii krzyżowej (np. `torch.nn.BCELoss`) ani sigmoidy (np.`torch.nn.functional.Sigmoid`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "class LogisticRegression:\n",
    "    def __init__(self, input_dim):\n",
    "        self.weight = None \n",
    "        self.bias = None \n",
    "        self.input_dim = input_dim\n",
    "    \n",
    "    def _sigmoid(self, x):\n",
    "        return 1/(1 + torch.exp(-x))\n",
    "        \n",
    "    def fit(self, X, y, lr=1e-6, num_steps=int(1e4)):\n",
    "        self.weight = torch.randn(self.input_dim, requires_grad=True)\n",
    "        self.bias = torch.randn((), requires_grad=True)\n",
    "        for idx in range(num_steps):\n",
    "            self.weight.requires_grad = True\n",
    "            self.bias.requires_grad = True\n",
    "\n",
    "            loss_val = self.loss(X, y)\n",
    "            loss_val = Variable(loss_val, requires_grad = True)\n",
    "            print(loss_val.shape)\n",
    "            loss_val.backward()\n",
    "            \n",
    "            w_grad = self.weight.grad\n",
    "            b_grad = self.bias.grad\n",
    "            with torch.no_grad():\n",
    "                self.weight = self.weight - lr * w_grad\n",
    "                self.bias = self.bias - lr * b_grad\n",
    "        \n",
    "    def predict_proba(self, X: torch.Tensor) -> torch.Tensor:\n",
    "        with torch.no_grad():\n",
    "            return  torch.matmul(X, self.weight) + self.bias\n",
    "            \n",
    "    def predict(self, X: torch.Tensor) -> torch.FloatTensor:\n",
    "        return self._sigmoid(X) > 0.5\n",
    "\n",
    "    def loss(self, X: torch.Tensor, y: torch.Tensor) -> torch.Tensor:\n",
    "        pred = self.predict_proba(X)\n",
    "        return torch.mean( -(y * torch.log(pred) + (1 - y)*torch.log(1 - pred)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([])\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for *: 'float' and 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/yk/k64l2mhn76v6pplzldkddm0c0000gr/T/ipykernel_44037/1248670355.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mchecker\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcheck_04_logistic_reg\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mLogisticRegression\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m~/Desktop/python/ml2022-23/lab/checker.py\u001B[0m in \u001B[0;36mcheck_04_logistic_reg\u001B[0;34m(lr_cls)\u001B[0m\n\u001B[1;32m    188\u001B[0m     \u001B[0minput_dataset\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mutils\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_classification_dataset_1d\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    189\u001B[0m     \u001B[0mlr\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlr_cls\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 190\u001B[0;31m     \u001B[0mlr\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minput_dataset\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput_dataset\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtarget\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlr\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m1e-3\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnum_steps\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m1e4\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    191\u001B[0m     \u001B[0mreturned\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlr\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpredict\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minput_dataset\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    192\u001B[0m     \u001B[0msave_path\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m\".checker/04/lr_dataset_1d.out.torch\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/var/folders/yk/k64l2mhn76v6pplzldkddm0c0000gr/T/ipykernel_44037/3480133043.py\u001B[0m in \u001B[0;36mfit\u001B[0;34m(self, X, y, lr, num_steps)\u001B[0m\n\u001B[1;32m     26\u001B[0m             \u001B[0mb_grad\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbias\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgrad\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     27\u001B[0m             \u001B[0;32mwith\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mno_grad\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 28\u001B[0;31m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mweight\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mweight\u001B[0m \u001B[0;34m-\u001B[0m \u001B[0mlr\u001B[0m \u001B[0;34m*\u001B[0m \u001B[0mw_grad\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     29\u001B[0m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbias\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbias\u001B[0m \u001B[0;34m-\u001B[0m \u001B[0mlr\u001B[0m \u001B[0;34m*\u001B[0m \u001B[0mb_grad\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     30\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mTypeError\u001B[0m: unsupported operand type(s) for *: 'float' and 'NoneType'"
     ]
    }
   ],
   "source": [
    "checker.check_04_logistic_reg(LogisticRegression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset_1d' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/yk/k64l2mhn76v6pplzldkddm0c0000gr/T/ipykernel_44037/250272008.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0mlogistic_reg\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mLogisticRegression\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m \u001B[0mlogistic_reg\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdataset_1d\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdataset_1d\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtarget\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlr\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m1e-3\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnum_steps\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m2e4\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      3\u001B[0m \u001B[0macc\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcalculate_accuracy\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlogistic_reg\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdataset_1d\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdataset_1d\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtarget\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"Accuracy\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0macc\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'dataset_1d' is not defined"
     ]
    }
   ],
   "source": [
    "logistic_reg = LogisticRegression(1)\n",
    "logistic_reg.fit(dataset_1d.data, dataset_1d.target, lr=1e-3, num_steps=int(2e4))\n",
    "acc = calculate_accuracy(logistic_reg, dataset_1d.data, dataset_1d.target)\n",
    "print(\"Accuracy\", acc)\n",
    "\n",
    "plot_dataset_1d(logistic_reg, dataset_1d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "grad can be implicitly created only for scalar outputs",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Input \u001B[0;32mIn [79]\u001B[0m, in \u001B[0;36m<cell line: 2>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m logistic_reg \u001B[38;5;241m=\u001B[39m LogisticRegression(\u001B[38;5;241m2\u001B[39m)\n\u001B[0;32m----> 2\u001B[0m \u001B[43mlogistic_reg\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdataset_2d\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdataset_2d\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtarget\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1e-2\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_steps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mint\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m2e4\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      3\u001B[0m acc \u001B[38;5;241m=\u001B[39m calculate_accuracy(logistic_reg, dataset_2d\u001B[38;5;241m.\u001B[39mdata, dataset_2d\u001B[38;5;241m.\u001B[39mtarget)\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAccuracy\u001B[39m\u001B[38;5;124m\"\u001B[39m, acc)\n",
      "Input \u001B[0;32mIn [76]\u001B[0m, in \u001B[0;36mLogisticRegression.fit\u001B[0;34m(self, X, y, lr, num_steps)\u001B[0m\n\u001B[1;32m     20\u001B[0m loss_val \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mloss(X, y)\n\u001B[1;32m     21\u001B[0m loss_val \u001B[38;5;241m=\u001B[39m Variable(loss_val, requires_grad \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m---> 22\u001B[0m \u001B[43mloss_val\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     24\u001B[0m w_grad \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mweight\u001B[38;5;241m.\u001B[39mgrad\n\u001B[1;32m     25\u001B[0m b_grad \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbias\u001B[38;5;241m.\u001B[39mgrad\n",
      "File \u001B[0;32m/opt/homebrew/anaconda3/envs/ml2022-23/lib/python3.9/site-packages/torch/_tensor.py:396\u001B[0m, in \u001B[0;36mTensor.backward\u001B[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[1;32m    387\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    388\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[1;32m    389\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[1;32m    390\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    394\u001B[0m         create_graph\u001B[38;5;241m=\u001B[39mcreate_graph,\n\u001B[1;32m    395\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs)\n\u001B[0;32m--> 396\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/homebrew/anaconda3/envs/ml2022-23/lib/python3.9/site-packages/torch/autograd/__init__.py:166\u001B[0m, in \u001B[0;36mbackward\u001B[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[1;32m    162\u001B[0m inputs \u001B[38;5;241m=\u001B[39m (inputs,) \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(inputs, torch\u001B[38;5;241m.\u001B[39mTensor) \u001B[38;5;28;01melse\u001B[39;00m \\\n\u001B[1;32m    163\u001B[0m     \u001B[38;5;28mtuple\u001B[39m(inputs) \u001B[38;5;28;01mif\u001B[39;00m inputs \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mtuple\u001B[39m()\n\u001B[1;32m    165\u001B[0m grad_tensors_ \u001B[38;5;241m=\u001B[39m _tensor_or_tensors_to_tuple(grad_tensors, \u001B[38;5;28mlen\u001B[39m(tensors))\n\u001B[0;32m--> 166\u001B[0m grad_tensors_ \u001B[38;5;241m=\u001B[39m \u001B[43m_make_grads\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_grads_batched\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m    167\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m retain_graph \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    168\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n",
      "File \u001B[0;32m/opt/homebrew/anaconda3/envs/ml2022-23/lib/python3.9/site-packages/torch/autograd/__init__.py:67\u001B[0m, in \u001B[0;36m_make_grads\u001B[0;34m(outputs, grads, is_grads_batched)\u001B[0m\n\u001B[1;32m     65\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m out\u001B[38;5;241m.\u001B[39mrequires_grad:\n\u001B[1;32m     66\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m out\u001B[38;5;241m.\u001B[39mnumel() \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m---> 67\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgrad can be implicitly created only for scalar outputs\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     68\u001B[0m     new_grads\u001B[38;5;241m.\u001B[39mappend(torch\u001B[38;5;241m.\u001B[39mones_like(out, memory_format\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mpreserve_format))\n\u001B[1;32m     69\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "\u001B[0;31mRuntimeError\u001B[0m: grad can be implicitly created only for scalar outputs"
     ]
    }
   ],
   "source": [
    "logistic_reg = LogisticRegression(2)\n",
    "logistic_reg.fit(dataset_2d.data, dataset_2d.target, lr=1e-2, num_steps=int(2e4))\n",
    "acc = calculate_accuracy(logistic_reg, dataset_2d.data, dataset_2d.target)\n",
    "print(\"Accuracy\", acc)\n",
    "\n",
    "plot_dataset_2d(logistic_reg, dataset_2d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Część 2: Reguła łańcuchowa i automatyczne różniczkowanie\n",
    "\n",
    "Przypomnijmy sobie regułę łańcuchową liczenia pochodnych. Jeśli mamy:\n",
    "$$ L(x) = g(f(x)), $$ \n",
    "to wtedy:\n",
    "\n",
    "$$ \\frac{dL(x)}{dx} = \\frac{dL(x)}{df(x)}\\frac{df(x)}{dx} $$\n",
    "\n",
    "W kontekście automatycznego różniczkowania w PyTorchu kluczowa jest tu właściwość, że do policzenia gradientu nie musimy nic wiedzieć o $g(x)$ o ile tylko znamy $\\frac{dL(x)}{df(x)}$. **Każdy moduł wie, jak policzyć swój gradient i dzięki temu można łańcuchowo liczyć pochodne skomplikowanych funkcji.**\n",
    "\n",
    "\n",
    "W PyTorchu każda funkcja, której używamy, ma zaimplementowane dwa podmoduły:\n",
    "* **Forward** - na podstawie podanego $x$ potrafi obliczyć $f(x)$. \n",
    "* **Backward** - na podstawie podanego $\\frac{dL(x)}{df(x)}$ potrafi policzyć $\\frac{dL(x)}{dx}$.\n",
    "\n",
    "Więcej o automatycznym różniczkowaniu można przeczytać w [dokumentacji PyTorcha](https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Przygotujmy sobie dane do testów\n",
    "input = torch.randn(30, 20, dtype=torch.double, requires_grad=True) * 3\n",
    "a = torch.randn(20, 30, requires_grad=True).double() * 2 - 5\n",
    "b = torch.randn(20, 30, requires_grad=True).double() + 6\n",
    "\n",
    "\n",
    "preds = torch.rand(30, requires_grad=True).double()\n",
    "labels_dist = torch.distributions.Bernoulli(probs=0.7)\n",
    "labels = labels_dist.sample([30]).double()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Przykład: różniczkowanie mnożenia\n",
    "Chcemy zaimplementować od nowa w PyTorchu fukcję $f(a, b) = a \\cdot b$, która potrafi policzyć swoje pochodne.\n",
    "\n",
    "W efekcie implementujemy obiekt typu `torch.autograd.Function` z metodami:\n",
    "* **Forward** \n",
    "    1. Dostaje na wejściu `a` oraz `b`\n",
    "    1. Zapamiętuje `a` oraz `b`, które przydadzą się później przy liczeniu pochodnej\n",
    "    2. Zwraca `a * b`\n",
    "* **Backward**\n",
    "    1. Dostaje na wejściu `grad_output` reprezentujące wartość $\\frac{dL(x)}{df(a, b)}$.\n",
    "    2. Wyjmuje z pamięci `a` oraz `b`.\n",
    "    3. Liczy swoją pochodną po a: $\\frac{df(a, b)}{da} = \\frac{da}{da} \\cdot b + a \\cdot \\frac{db}{da} = 1\\cdot b + a\\cdot 0 = b$\n",
    "    4. Liczy swoją pochodną po b: $\\frac{df(a, b)}{db} = \\frac{da}{db} \\cdot b + a \\cdot \\frac{db}{db} = 0\\cdot b + a\\cdot 1 = a$\n",
    "    5. Zwraca pochodne $\\frac{dL(x)}{df(a, b)} \\frac{df(a, b)}{da}$ oraz $\\frac{dL(x)}{df(a, b)} \\frac{df(a, b)}{db}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MyProduct(torch.autograd.Function):\n",
    "    \n",
    "    @staticmethod\n",
    "    def forward(self, a, b):\n",
    "        self.save_for_backward(a, b)\n",
    "        return a * b\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(self, grad_output):\n",
    "        # Wyjmujemy z pamięci a oraz b\n",
    "        a, b = self.saved_tensors\n",
    "        # Liczymy pochodną po a\n",
    "        a_grad = b\n",
    "        # Liczymy pochodną po b\n",
    "        b_grad = a\n",
    "        \n",
    "        # Zwracamy \"łańcuchowe\" pochodne\n",
    "        return grad_output * a_grad, grad_output * b_grad\n",
    "    \n",
    "prod_fn = MyProduct.apply\n",
    "torch.autograd.gradcheck(prod_fn, (a, b), eps=1e-3, atol=1e-2, rtol=1e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie 3 (3 pkt.)\n",
    "Proszę zaimplementować backward pass w następujących funkcjach:\n",
    "* MyAdd(a, b): a + b - $\\frac{df}{da} = 1, \\frac{df}{db} = 1$\n",
    "* MyDiv(a, b): a / b - $\\frac{df}{da} = \\frac{1}{b}, \\frac{df}{db}= -\\frac{a}{b^2}$\n",
    "* MySigmoid(input): tak jak w zadaniu 2  - $\\frac{df}{dz} = \\sigma(z)(1 - \\sigma(z)) = \\frac{1}{1 + \\exp(-z)} \\cdot (1 - \\frac{1}{1 + \\exp(-z))})$\n",
    "* BCE(preds, labels): tak jak w zadaniu 2 - $\\frac{df}{d\\hat{y}} = \\frac{1}{N} (-\\frac{y}{\\hat{y}} + \\frac{1 - y}{1 - \\hat{y}}),$ gdzie $y$ to etykieta a $\\hat{y}$ to predykcja.\n",
    "\n",
    "(jako że nie liczymy tutaj pochodnej po etykietach, można zwrócić `grad_labels = None`)\n",
    "\n",
    "**Zdarza się, że funkcja do testowania gradientu `torch.autograd.gradcheck` będzie wyrzucała błędy przez niedokładności numeryczne. Proszę odświeżyć dane i spróbować jeszcze raz.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MyAdd(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(self, a, b):\n",
    "        self.save_for_backward(a, b)\n",
    "        return a + b\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(self, grad_output):\n",
    "        a, b = self.saved_tensors\n",
    "        return grad_output * 1, grad_output * 1\n",
    "\n",
    "add_fn = MyAdd.apply\n",
    "torch.autograd.gradcheck(add_fn, (a, b), eps=1e-3, atol=1e-2, rtol=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MyDiv(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(self, a, b):\n",
    "        self.save_for_backward(a, b)\n",
    "        return a / b\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(self, grad_output):\n",
    "        a, b = self.saved_tensors\n",
    "        return grad_output * 1/b, grad_output * -a/(b*b)\n",
    "\n",
    "div_fn = MyDiv.apply\n",
    "torch.autograd.gradcheck(div_fn, (a, b), eps=1e-3, atol=1e-2, rtol=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MySigmoid(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(self, input_):\n",
    "        self.save_for_backward(input_)\n",
    "        return 1/(1 + torch.exp(-input_))\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(self, grad_output):\n",
    "        input_, = self.saved_tensors\n",
    "        return 1/(1 + torch.exp(-input_)) * (1 - 1/(1 + torch.exp(-input_))) * grad_output\n",
    "    \n",
    "\n",
    "sigmoid_fn = MySigmoid.apply\n",
    "torch.autograd.gradcheck(sigmoid_fn, input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Boolean value of Tensor with more than one value is ambiguous",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/yk/k64l2mhn76v6pplzldkddm0c0000gr/T/ipykernel_44037/3606292057.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     12\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     13\u001B[0m \u001B[0mbce_fn\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mMyBinaryCrossEntropy\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mapply\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 14\u001B[0;31m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mautograd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgradcheck\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mbce_fn\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mpreds\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlabels\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0meps\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m1e-3\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0matol\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m1e-2\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrtol\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m1e-1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m/usr/local/lib/python3.7/site-packages/torch/autograd/gradcheck.py\u001B[0m in \u001B[0;36mgradcheck\u001B[0;34m(func, inputs, eps, atol, rtol, raise_exception, check_sparse_nnz, nondet_tol, check_undefined_grad, check_grad_dtypes, check_batched_grad, check_batched_forward_grad, check_forward_ad, check_backward_ad, fast_mode)\u001B[0m\n\u001B[1;32m   1416\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0;32mFalse\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1417\u001B[0m     \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1418\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0m_gradcheck_helper\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m**\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1419\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1420\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.7/site-packages/torch/autograd/gradcheck.py\u001B[0m in \u001B[0;36m_gradcheck_helper\u001B[0;34m(func, inputs, eps, atol, rtol, check_sparse_nnz, nondet_tol, check_undefined_grad, check_grad_dtypes, check_batched_grad, check_batched_forward_grad, check_forward_ad, check_backward_ad, fast_mode)\u001B[0m\n\u001B[1;32m   1425\u001B[0m     \u001B[0m_check_inputs\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtupled_inputs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcheck_sparse_nnz\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1426\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1427\u001B[0;31m     \u001B[0mfunc_out\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0mtupled_inputs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1428\u001B[0m     \u001B[0moutputs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_differentiable_outputs\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfunc_out\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1429\u001B[0m     \u001B[0m_check_outputs\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0moutputs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/var/folders/yk/k64l2mhn76v6pplzldkddm0c0000gr/T/ipykernel_44037/3606292057.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, preds, labels, bias)\u001B[0m\n\u001B[1;32m      3\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpreds\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlabels\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbias\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msave_for_backward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpreds\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlabels\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 5\u001B[0;31m         \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnn\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mBCELoss\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpreds\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlabels\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbias\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      6\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      7\u001B[0m     \u001B[0;34m@\u001B[0m\u001B[0mstaticmethod\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.7/site-packages/torch/nn/modules/loss.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, weight, size_average, reduce, reduction)\u001B[0m\n\u001B[1;32m    614\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    615\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m__init__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mweight\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mOptional\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mTensor\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msize_average\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mreduce\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mreduction\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mstr\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m'mean'\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 616\u001B[0;31m         \u001B[0msuper\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mBCELoss\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__init__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mweight\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msize_average\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mreduce\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mreduction\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    617\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    618\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mTensor\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtarget\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mTensor\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0mTensor\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.7/site-packages/torch/nn/modules/loss.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, weight, size_average, reduce, reduction)\u001B[0m\n\u001B[1;32m     28\u001B[0m \u001B[0;32mclass\u001B[0m \u001B[0m_WeightedLoss\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0m_Loss\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     29\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m__init__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mweight\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mOptional\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mTensor\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msize_average\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mreduce\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mreduction\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mstr\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m'mean'\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 30\u001B[0;31m         \u001B[0msuper\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0m_WeightedLoss\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__init__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msize_average\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mreduce\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mreduction\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     31\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mregister_buffer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'weight'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mweight\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     32\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mweight\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mOptional\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mTensor\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.7/site-packages/torch/nn/modules/loss.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, size_average, reduce, reduction)\u001B[0m\n\u001B[1;32m     21\u001B[0m         \u001B[0msuper\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0m_Loss\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__init__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     22\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0msize_average\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m \u001B[0;32mor\u001B[0m \u001B[0mreduce\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 23\u001B[0;31m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mreduction\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mstr\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_Reduction\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlegacy_get_string\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msize_average\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mreduce\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     24\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     25\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mreduction\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mreduction\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.7/site-packages/torch/nn/_reduction.py\u001B[0m in \u001B[0;36mlegacy_get_string\u001B[0;34m(size_average, reduce, emit_warning)\u001B[0m\n\u001B[1;32m     33\u001B[0m         \u001B[0mreduce\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mTrue\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     34\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 35\u001B[0;31m     \u001B[0;32mif\u001B[0m \u001B[0msize_average\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0mreduce\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     36\u001B[0m         \u001B[0mret\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m'mean'\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     37\u001B[0m     \u001B[0;32melif\u001B[0m \u001B[0mreduce\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: Boolean value of Tensor with more than one value is ambiguous"
     ]
    }
   ],
   "source": [
    "class MyBinaryCrossEntropy(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(self, preds, labels, bias=None):\n",
    "        self.save_for_backward(preds, labels)\n",
    "        torch.nn.BCELoss(preds, labels, bias)\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(self, grad_output):\n",
    "        preds, labels = self.saved_tensors\n",
    "        grad_labels = None\n",
    "        return (1/preds.shape[0] * (-labels/preds + (1-labels)/(1-preds) )) *  grad_output\n",
    "\n",
    "bce_fn = MyBinaryCrossEntropy.apply\n",
    "torch.autograd.gradcheck(bce_fn, (preds, labels), eps=1e-3, atol=1e-2, rtol=1e-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sprawdźmy nasze moduły w prostej pętli treningowej:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Boolean value of Tensor with more than one value is ambiguous",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/yk/k64l2mhn76v6pplzldkddm0c0000gr/T/ipykernel_44037/334619911.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     19\u001B[0m     \u001B[0mlogit\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0madd_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mprod_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mweight\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mX\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbias\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     20\u001B[0m     \u001B[0mpred\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0msigmoid_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlogit\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 21\u001B[0;31m     \u001B[0mloss\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mbce_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpred\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     22\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     23\u001B[0m     \u001B[0;31m# Gradient przechodzi przez funkcję backward każdego modułu\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/var/folders/yk/k64l2mhn76v6pplzldkddm0c0000gr/T/ipykernel_44037/4162110160.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, preds, labels, bias)\u001B[0m\n\u001B[1;32m      3\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpreds\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlabels\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbias\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msave_for_backward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpreds\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlabels\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 5\u001B[0;31m         \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnn\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mBCELoss\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpreds\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlabels\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbias\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      6\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      7\u001B[0m     \u001B[0;34m@\u001B[0m\u001B[0mstaticmethod\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.7/site-packages/torch/nn/modules/loss.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, weight, size_average, reduce, reduction)\u001B[0m\n\u001B[1;32m    614\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    615\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m__init__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mweight\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mOptional\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mTensor\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msize_average\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mreduce\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mreduction\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mstr\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m'mean'\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 616\u001B[0;31m         \u001B[0msuper\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mBCELoss\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__init__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mweight\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msize_average\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mreduce\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mreduction\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    617\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    618\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mTensor\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtarget\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mTensor\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0mTensor\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.7/site-packages/torch/nn/modules/loss.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, weight, size_average, reduce, reduction)\u001B[0m\n\u001B[1;32m     28\u001B[0m \u001B[0;32mclass\u001B[0m \u001B[0m_WeightedLoss\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0m_Loss\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     29\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m__init__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mweight\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mOptional\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mTensor\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msize_average\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mreduce\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mreduction\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mstr\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m'mean'\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 30\u001B[0;31m         \u001B[0msuper\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0m_WeightedLoss\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__init__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msize_average\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mreduce\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mreduction\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     31\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mregister_buffer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'weight'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mweight\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     32\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mweight\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mOptional\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mTensor\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.7/site-packages/torch/nn/modules/loss.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, size_average, reduce, reduction)\u001B[0m\n\u001B[1;32m     21\u001B[0m         \u001B[0msuper\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0m_Loss\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__init__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     22\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0msize_average\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m \u001B[0;32mor\u001B[0m \u001B[0mreduce\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 23\u001B[0;31m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mreduction\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mstr\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_Reduction\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlegacy_get_string\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msize_average\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mreduce\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     24\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     25\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mreduction\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mreduction\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.7/site-packages/torch/nn/_reduction.py\u001B[0m in \u001B[0;36mlegacy_get_string\u001B[0;34m(size_average, reduce, emit_warning)\u001B[0m\n\u001B[1;32m     33\u001B[0m         \u001B[0mreduce\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mTrue\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     34\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 35\u001B[0;31m     \u001B[0;32mif\u001B[0m \u001B[0msize_average\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0mreduce\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     36\u001B[0m         \u001B[0mret\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m'mean'\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     37\u001B[0m     \u001B[0;32melif\u001B[0m \u001B[0mreduce\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: Boolean value of Tensor with more than one value is ambiguous"
     ]
    }
   ],
   "source": [
    "# Przygotowujemy prosty dataset\n",
    "X = torch.cat([\n",
    "    torch.randn(10) * 3 + 2,\n",
    "    torch.randn(10) * 3 + 12\n",
    "])\n",
    "y = torch.cat([torch.zeros(10), torch.ones(10)])\n",
    "\n",
    "\n",
    "# Inicjalizujemy zmienne\n",
    "weight = torch.randn((), requires_grad=True)\n",
    "bias = torch.randn((), requires_grad=True)\n",
    "\n",
    "lr = 1e-1\n",
    "for idx in range(10000):\n",
    "    weight.requires_grad = True\n",
    "    bias.requires_grad = True\n",
    "    \n",
    "    # Liczymy funkcję kosztu za pomocą naszych modułów\n",
    "    logit = add_fn(prod_fn(weight, X), bias)\n",
    "    pred = sigmoid_fn(logit)\n",
    "    loss = bce_fn(pred, y)\n",
    "    \n",
    "    # Gradient przechodzi przez funkcję backward każdego modułu\n",
    "    loss.backward()\n",
    "    \n",
    "    # Wyciągamy gradienty\n",
    "    w_grad = weight.grad\n",
    "    b_grad = bias.grad\n",
    "    \n",
    "    # Wykonujemy krok metody spadku gradientu\n",
    "    with torch.no_grad():\n",
    "        weight = weight - lr * w_grad\n",
    "        bias = bias - lr * b_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X, np.zeros_like(X) + 0.5, c=y.numpy())\n",
    "\n",
    "linspace = torch.linspace(-5, 15, steps=100).view(-1, 1)\n",
    "with torch.no_grad():\n",
    "    plt.plot(\n",
    "        linspace.numpy().ravel(),\n",
    "        sigmoid_fn(add_fn(prod_fn(weight, linspace), bias)).detach().numpy(),\n",
    "        label=\"p(y=0 | x)\"\n",
    "    )\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dygresje\n",
    "* Istnieją inne frameworki do deep learningu poza PyTorchem. Szczególnie popularny jest teraz TensorFlow (często używany razem z Kerasem). Popularne w przeszłości, ale wciąż poniekąd istotne są: Theano, Caffe, MXNet, Jax.\n",
    "* Sigmoid staje się bardziej naturalny, kiedy myślimy o outputach z modelu liniowego jako o logarytmie szans (*log-odds* albo *logits*). [Więcej tutaj](https://en.wikipedia.org/wiki/Logistic_regression#Logistic_model). "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
